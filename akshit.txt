THE SORTING HAT
　　The door swung open at once. A tall, black-haired witch in emerald-green robes stood there. She had a very stern face and Harry's first thought was that this was not someone to cross.
　　"The firs' years, Professor McGonagall," said Hagrid.
　　"Thank you, Hagrid. I will take them from here."
　　She pulled the door wide. The entrance hall was so big you could have fit the whole of the Dursleys' house in it. The stone walls were lit with flaming torches like the ones at Gringotts, the ceiling was too high to make out, and a magnificent marble staircase facing them led to the upper floors.
　　They followed Professor McGonagall across the flagged stone floor. Harry could hear the drone of hundreds of voices from a doorway to the right -the rest of the school must already be here -- but Professor McGonagall showed the first years into a small, empty chamber off the hall. They crowded in, standing rather closer together than they would usually have done, peering about nervously.
　　"Welcome to Hogwarts," said Professor McGonagall. "The start-of-term banquet will begin shortly, but before you take your seats in the Great Hall, you will be sorted into your houses. The Sorting is a very important ceremony because, while you are here, your house will be something like your family within Hogwarts. You will have classes with the rest of your house, sleep in your house dormitory, and spend free time in your house common room.
　　"The four houses are called Gryffindor, Hufflepuff, Ravenclaw, and Slytherin. Each house has its own noble history and each has produced outstanding witches and wizards. While you are at Hogwarts, your triumphs will earn your house points, while any rulebreaking will lose house points. At the end of the year, the house with the most points is awarded the house cup, a great honor. I hope each of you will be a credit to whichever house becomes yours.
　　"The Sorting Ceremony will take place in a few minutes in front of the rest of the school. I suggest you all smarten yourselves up as much as you can while you are waiting."
　　Her eyes lingered for a moment on Neville's cloak, which was fastened under his left ear, and on Ron's smudged nose. Harry nervously tried to flatten his hair.
　　"I shall return when we are ready for you," said Professor McGonagall. "Please wait quietly."
　　She left the chamber. Harry swallowed.
　　"How exactly do they sort us into houses?" he asked Ron.
　　"Some sort of test, I think. Fred said it hurts a lot, but I think he was joking."
　　Harry's heart gave a horrible jolt. A test? In front of the whole school? But he didn't know any magic yet -- what on earth would he have to do? He hadn't expected something like this the moment they arrived. He looked around anxiously and saw that everyone else looked terrified, too. No one was talking much except Hermione Granger, who was whispering very fast about all the spells she'd learned and wondering which one she'd need. Harry tried hard not to listen to her. He'd never been more nervous, never, not even when he'd had to take a school report home to the Dursleys saying that he'd somehow turned his teacher's wig blue. He kept his eyes fixed on the door. Any second now, Professor McGonagall would come back and lead him to his doom.
　　Then something happened that made him jump about a foot in the air -- several people behind him screamed.
　　"What the --?"
　　He gasped. So did the people around him. About twenty ghosts had just streamed through the back wall. Pearly-white and slightly transparent, they glided across the room talking to one another and hardly glancing at the first years. They seemed to be arguing. What looked like a fat little monk was saying: "Forgive and forget, I say, we ought to give him a second chance --"
　　"My dear Friar, haven't we given Peeves all the chances he deserves? He gives us all a bad name and you know, he's not really even a ghost -- I say, what are you all doing here?"
　　A ghost wearing a ruff and tights had suddenly noticed the first years.
　　Nobody answered.
　　"New students!" said the Fat Friar, smiling around at them. "About to be Sorted, I suppose?"
　　A few people nodded mutely.
　　"Hope to see you in Hufflepuff!" said the Friar. "My old house, you know."
　　"Move along now," said a sharp voice. "The Sorting Ceremony's about to start."
　　Professor McGonagall had returned. One by one, the ghosts floated away through the opposite wall.
　　"Now, form a line," Professor McGonagall told the first years, "and follow me."
　　Feeling oddly as though his legs had turned to lead, Harry got into line behind a boy with sandy hair, with Ron behind him, and they walked out of the chamber, back across the hall, and through a pair of double doors into the Great Hall.
　　Harry had never even imagined such a strange and splendid place. It was lit by thousands and thousands of candles that were floating in midair over four long tables, where the rest of the students were sitting. These tables were laid with glittering golden plates and goblets. At the top of the hall was another long table where the teachers were sitting. Professor McGonagall led the first years up here, so that they came to a halt in a line facing the other students, with the teachers behind them. The hundreds of faces staring at them looked like pale lanterns in the flickering candlelight. Dotted here and there among the students, the ghosts shone misty silver. Mainly to avoid all the staring eyes, Harry looked upward and saw a velvety black ceiling dotted with stars. He heard
　　Hermione whisper, "Its bewitched to look like the sky outside. I read about it in Hogwarts, A History."
　　It was hard to believe there was a ceiling there at all, and that the Great Hall didn't simply open on to the heavens.
　　Harry quickly looked down again as Professor McGonagall silently placed a four-legged stool in front of the first years. On top of the stool she put a pointed wizard's hat. This hat was patched and frayed and extremely dirty. Aunt Petunia wouldn't have let it in the house.
　　Maybe they had to try and get a rabbit out of it, Harry thought wildly, that seemed the sort of thing -- noticing that everyone in the hall was now staring at the hat, he stared at it, too. For a few seconds, there was complete silence. Then the hat twitched. A rip near the brim opened wide like a mouth -- and the hat began to sing:
　　"Oh, you may not think I'm pretty,
　　But don't judge on what you see,
　　I'll eat myself if you can find
　　A smarter hat than me.
　　You can keep your bowlers black,
　　Your top hats sleek and tall,
　　For I'm the Hogwarts Sorting Hat
　　And I can cap them all.
　　There's nothing hidden in your head
　　The Sorting Hat can't see,
　　So try me on and I will tell you
　　Where you ought to be.
　　You might belong in Gryffindor,
　　Where dwell the brave at heart,
　　Their daring, nerve, and chivalry Set Gryffindors apart;
　　You might belong in Hufflepuff,
　　Where they are just and loyal,
　　Those patient Hufflepuffis are true And unafraid of toil;
　　Or yet in wise old Ravenclaw,
　　if you've a ready mind,
　　 Where those of wit and learning,
　　Will always find their kind;
　　Or perhaps in Slytherin
　　You'll make your real friends,
　　Those cunning folk use any means
　　To achieve their ends.
　　So put me on! Don't be afraid!
　　And don't get in a flap!
　　You're in safe hands (though I have none)
　　For I'm a Thinking Cap!"
　　The whole hall burst into applause as the hat finished its song. It bowed to each of the four tables and then became quite still again.
　　"So we've just got to try on the hat!" Ron whispered to Harry. "I'll kill Fred, he was going on about wrestling a troll."
　　Harry. smiled weakly. Yes, trying on the hat was a lot better than having to do a spell, but he did wish they could have tried it on without everyone watching. The hat seemed to be asking rather alot; Harry didn't feel brave or quick-witted or any of it at the moment. If only the hat had mentioned a house for people who felt a bit queasy, that would have been the one for him.
　　Professor McGonagall now stepped forward holding a long roll of parchment.
　　"When I call your name, you will put on the hat and sit on the stool to be sorted," she said. "Abbott, Hannah!"
　　A pink-faced girl with blonde pigtails stumbled out of line, put on the hat, which fell right down over her eyes, and sat down. A moments pause --
　　"HUFFLEPUFF!" shouted the hat.
　　The table on the right cheered and clapped as Hannah went to sit down at the Hufflepuff table. Harry saw the ghost of the Fat Friar waving merrily at her.
　　"Bones, Susan!"
　　"HUFFLEPUFF!" shouted the hat again, and Susan scuttled off to sit next to Hannah.
　　"Boot, Terry!"
　　"RAVENCLAW!"
　　The table second from the left clapped this time; several Ravenclaws stood up to shake hands with Terry as he joined them.
　　" Brocklehurst, Mandy" went to Ravenclaw too, but "Brown, Lavender" became the first new Gryffindor, and the table on the far left exploded with cheers; Harry could see Ron's twin brothers catcalling.
　　"Bulstrode, Millicent" then became a Slytherin. Perhaps it was Harry's imagination, after all he'd heard about Slytherin, but he thought they looked like an unpleasant lot. He was starting to feel definitely sick now. He remembered being picked for teams during gym at his old school. He had always been last to be chosen, not because he was no good, but because no one wanted Dudley to think they liked him.
　　"Finch-Fletchley, Justin!"
　　"HUFFLEPUFF!"
　　Sometimes, Harry noticed, the hat shouted out the house at once, but at others it took a little while to decide. "Finnigan, Seamus," the sandy-haired boy next to Harry in the line, sat on the stool for almost a whole minute before the hat declared him a Gryffindor.
　　"Granger, Hermione!"
　　Hermione almost ran to the stool and jammed the hat eagerly on her head.
　　"GRYFFINDOR!" shouted the hat. Ron groaned.
　　A horrible thought struck Harry, as horrible thoughts always do when you're very nervous. What if he wasn't chosen at all? What if he just sat there with the hat over his eyes for ages, until Professor McGonagall jerked it off his head and said there had obviously been a mistake and he'd better get back on the train?
　　When Neville Longbottom, the boy who kept losing his toad, was called, he fell over on his way to the stool. The hat took a long time to decide with Neville. When it finally shouted, "GRYFFINDOR," Neville ran off still wearing it, and had to jog back amid gales of laughter to give it to "MacDougal, Morag."
　　Malfoy swaggered forward when his name was called and got his wish at once: the hat had barely touched his head when it screamed, "SLYTHERIN!"
　　Malfoy went to join his friends Crabbe and Goyle, looking pleased with himself.
　　There weren't many people left now. "Moon" "Nott" "Parkinson" then a pair of twin girls, "Patil" and "Patil" then "Perks, Sally-Anne" and then, at last -- "Potter, Harry!"
　　As Harry stepped forward, whispers suddenly broke out like little hissing fires all over the hall.
　　"Potter, did she say?"
　　The Harry Potter?"
　　The last thing Harry saw before the hat dropped over his eyes was the hall full of people craning to get a good look at him. Next second he was looking at the black inside of the hat. He waited.
　　Hmm," said a small voice in his ear. "Difficult. Very difficult. Plenty of courage, I see. Not a bad mind either. There's talent, A my goodness, yes -- and a nice thirst to prove yourself, now that's interesting.... So where shall I put you?"
　　Harry gripped the edges of the stool and thought, Not Slytherin, not Slytherin.
　　"Not Slytherin, eh?" said the small voice. "Are you sure? You could be great, you know, it's all here in your head, and Slytherin will help you on the way to greatness, no doubt about that -- no? Well, if you're sure -- better be GRYFFINDOR!"
　　Harry heard the hat shout the last word to the whole hall. He took off the hat and walked shakily toward the Gryffindor table. He was so relieved to have been chosen and not put in Slytherin, he hardly noticed that he was getting the loudest cheer yet. Percy the Prefect got up and shook his hand vigorously, while the Weasley twins yelled, "We got Potter! We got Potter!" Harry sat down opposite the ghost in the ruff he'd seen earlier. The ghost patted his arm, giving Harry the sudden, horrible feeling he'd just plunged it into a bucket of ice-cold water.
　　He could see the High Table properly now. At the end nearest him sat Hagrid, who caught his eye and gave him the thumbs up. Harry grinned back. And there, in the center of the High Table, in a large gold chair, sat Albus Dumbledore. Harry recognized him at once from the card he'd gotten out of the Chocolate Frog on the train. Dumbledore's silver hair was the only thing in the whole hall that shone as brightly as the ghosts. Harry spotted Professor Quirtell, too, the nervous young man from the Leaky Cauldron. He was looking very peculiar in a large purple turban.
　　And now there were only three people left to be sorted. "Thomas, Dean," a Black boy even taller than Ron, joined Harry at the Gryffindor table. "Turpin, Lisa," became a Ravenclaw and then it was Ron's turn. He was pale green by now. Harry crossed his fingers under the table and a second later the hat had shouted, "GRYFFINDOR!"
　　Harry clapped loudly with the rest as Ron collapsed into the chair next to him.
　　"Well done, Ron, excellent," said Percy Weasley Pompously across Harry as "Zabini, Blaise," was made a Slytherin. Professor McGonagall rolled up her scroll and took the Sorting Hat away.
　　Harry looked down at his empty gold plate. He had only just realized how hungry he was. The pumpkin pasties seemed ages ago.
　　Albus Dumbledore had gotten to his feet. He was beaming at the students, his arms opened wide, as if nothing could have pleased him more than to see them all there.
　　"Welcome," he said. "Welcome to a new year at Hogwarts! Before we begin our banquet, I would like to say a few words. And here they are: Nitwit! Blubber! Oddment! Tweak!
　　"Thank you!"
　　He sat back down. Everybody clapped and cheered. Harry didn't know whether to laugh or not.
　　 "Is he -- a bit mad?" he asked Percy uncertainly.
　　"Mad?" said Percy airily. "He's a genius! Best wizard in the world! But he is a bit mad, yes. Potatoes, Harry?"
　　Harry's mouth fell open. The dishes in front of him were now piled with food. He had never seen so many things he liked to eat on one table: roast beef, roast chicken, pork chops and lamb chops, sausages, bacon and steak, boiled potatoes, roast potatoes, fries, Yorkshire pudding, peas, carrots, gravy, ketchup, and, for some strange reason, peppermint humbugs.
　　The Dursleys had never exactly starved Harry, but he'd never been allowed to eat as much as he liked. Dudley had always taken anything that Harry really wanted, even if It made him sick. Harry piled his plate with a bit of everything except the peppermints and began to eat. It was all delicious.
　　"That does look good," said the ghost in the ruff sadly, watching Harry cut up his steak,
　　"Can't you --?"
　　I haven't eaten for nearly four hundred years," said the ghost. "I don't need to, of course, but one does miss it. I don't think I've in troduced myself? Sir Nicholas de Mimsy-Porpington at your service. Resident ghost of Gryffindor Tower."
　　"I know who you are!" said Ron suddenly. "My brothers told me about you -- you're Nearly Headless Nick!"
　　"I would prefer you to call me Sir Nicholas de Mimsy --" the ghost began stiffly, but sandy-haired Seamus Finnigan interrupted.
　　"Nearly Headless? How can you be nearly headless?"
　　Sir Nicholas looked extremely miffed, as if their little chat wasn't going at all the way he wanted.
　　"Like this," he said irritably. He seized his left ear and pulled. His whole head swung off his neck and fell onto his shoulder as if it was on a hinge. Someone had obviously tried to behead him, but not done it properly. Looking pleased at the stunned looks on their faces, Nearly Headless Nick flipped his head back onto his neck, coughed, and said, "So -- new Gryffindors! I hope you're going to help us win the house championship this year? Gryffindors have never gone so long without winning. Slytherins have got the cup six years in a row! The Bloody Baron's becoming almost unbearable -- he's the Slytherin ghost."
　　Harry looked over at the Slytherin table and saw a horrible ghost sitting there, with blank staring eyes, a gaunt face, and robes stained with silver blood. He was right next to Malfoy who, Harry was pleased to see, didn't look too pleased with the seating arrangements.
　　"How did he get covered in blood?" asked Seamus with great interest.
　　"I've never asked," said Nearly Headless Nick delicately.
　　When everyone had eaten as much as they could, the remains of the food faded from the plates, leaving them sparkling clean as before. A moment later the desserts appeared. Blocks of ice cream in every flavor you could think of, apple pies, treacle tarts, chocolate eclairs and jam doughnuts, trifle, strawberries, Jell-O, rice pudding -- "
　　As Harry helped himself to a treacle tart, the talk turned to their families.
　　"I'm half-and-half," said Seamus. "Me dad's a Muggle. Mom didn't tell him she was a witch 'til after they were married. Bit of a nasty shock for him."
　　The others laughed.
　　"What about you, Neville?" said Ron.
　　"Well, my gran brought me up and she's a witch," said Neville, "but the family thought I was all- Muggle for ages. My Great Uncle Algie kept trying to catch me off my guard and force some magic out of me -- he pushed me off the end of Blackpool pier once, I nearly drowned -- but nothing happened until I was eight. Great Uncle Algie came round for dinner, and he was hanging me out of an upstairs window by the ankles when my Great Auntie Enid offered him a meringue and he accidentally let go. But I bounced -- all the way down the garden and into the road. They were all really pleased, Gran was crying, she was so happy. And you should have seen their faces when I got in here -- they thought I might not be magic enough to come, you see. Great Uncle Algie was so pleased he bought me my toad."
　　On Harry's other side, Percy Weasley and Hermione were talking about lessons ("I do hope they start right away, there's so much to learn, I'm particularly interested in Transfiguration, you know, turning something into something else, of course, it's supposed to be very difficult-"; "You'll be starting small, just matches into needles and that sort of thing -- ").
　　Harry, who was starting to feel warm and sleepy, looked up at
　　the High Table again. Hagrid was drinking deeply from his goblet. Professor McGonagall was talking to Professor Dumbledore. Professor Quirrell, in his absurd turban, was talking to a teacher with greasy black hair, a hooked nose, and sallow skin.
　　It happened very suddenly. The hook-nosed teacher looked past Quirrell's turban straight into Harry's eyes -- and a sharp, hot pain shot across the scar on Harry's forehead.
　　"Ouch!" Harry clapped a hand to his head.
　　"What is it?" asked Percy.
　　"N-nothing."
　　The pain had gone as quickly as it had come. Harder to shake off was the feeling Harry had gotten from the teacher's look -- a feeling that he didn't like Harry at all.
　　"Who's that teacher talking to Professor Quirrell?" he asked Percy.
　　"Oh, you know Quirrell already, do you? No wonder he's looking so nervous, that's Professor Snape. He teaches Potions, but he doesn't want to -- everyone knows he's after Quirrell's job. Knows an awful lot about the Dark Arts, Snape."
　　Harry watched Snape for a while, but Snape didn't look at him again.
　　At last, the desserts too disappeared, and Professor Dumbledore got to his feet again. The hall fell silent.
　　"Ahern -- just a few more words now that we are all fed and watered. I have a few start-of-term notices to give you.
　　"First years should note that the forest on the grounds is forbidden to all pupils. And a few of our older students would do well to remember that as well."
　　Dumbledore's twinkling eyes flashed in the direction of the Weasley twins.
　　"I have also been asked by Mr. Filch, the caretaker, to remind you all that no magic should be used between classes in the corridors.
　　"Quidditch trials will be held in the second week of the term. Anyone interested in playing for their house teams should contact Madam Hooch.
　　"And finally, I must tell you that this year, the third-floor corridor on the right-hand side is out of bounds to everyone who does not wish to die a very painful death."
　　Harry laughed, but he was one of the few who did.
　　"He's not serious?" he muttered to Percy.
　　"Must be," said Percy, frowning at Dumbledore. "It's odd, because he usually gives us a reason why we're not allowed to go somewhere -- the forest's full of dangerous beasts, everyone knows that. I do think he might have told us prefects, at least."
　　"And now, before we go to bed, let us sing the school song!" cried Dumbledore. Harry noticed that the other teachers' smiles had become rather fixed.
　　Dumbledore gave his wand a little flick, as if he was trying to get a fly off the end, and a long golden ribbon flew out of it, which rose high above the tables and twisted itself, snakelike, into words.
　　"Everyone pick their favorite tune," said Dumbledore, "and off we go!" And the school bellowed:
　　"Hogwarts, Hogwarts, Hoggy Warty Hogwarts,
　　Teach us something please,
　　Whether we be old and bald
　　Or young with scabby knees,
　　Our heads could do with filling
　　With some interesting stuff,
　　For now they're bare and full of air,
　　Dead flies and bits of fluff,
　　So teach us things worth knowing,
　　Bring back what we've forgot,
　　just do your best, we'll do the rest,
　　And learn until our brains all rot.
　　Everybody finished the song at different times. At last, only the Weasley twins were left singing along to a very slow funeral march. Dumbledore conducted their last few lines with his wand and when they had finished, he was one of those who clapped loudest.
　　"Ah, music," he said, wiping his eyes. "A magic beyond all we do here! And now, bedtime. Off you trot!"
　　The Gryffindor first years followed Percy through the chattering crowds, out of the Great Hall, and up the marble staircase. Harry's legs were like lead again, but only because he was so tired and full of food. He was too sleepy even to be surprised that the people in the portraits along the corridors whispered and pointed as they passed, or that twice Percy led them through doorways hidden behind sliding panels and hanging tapestries. They climbed more staircases, yawning and dragging their feet, and Harry was just wondering how much farther they had to go when they came to a sudden halt.
　　A bundle of walking sticks was floating in midair ahead of them, and as Percy took a step toward them they started throwing themselves at him.
　　"Peeves," Percy whispered to the first years. "A poltergeist." He raised his voice, "Peeves -- show yourself"
　　A loud, rude sound, like the air being let out of a balloon, answered.
　　"Do you want me to go to the Bloody Baron?"
　　There was a pop, and a little man with wicked, dark eyes and a wide mouth appeared, floating cross- legged in the air, clutching the walking sticks.
　　"Oooooooh!" he said, with an evil cackle. "Ickle Firsties! What fun!"
　　He swooped suddenly at them. They all ducked.
　　"Go away, Peeves, or the Baron'll hear about this, I mean it!" barked Percy.
　　Peeves stuck out his tongue and vanished, dropping the walking sticks on Neville's head. They heard him zooming away, rattling coats of armor as he passed.
　　"You want to watch out for Peeves," said Percy, as they set off again. "The Bloody Baron's the only one who can control him, he won't even listen to us prefects. Here we are."
　　At the very end of the corridor hung a portrait of a very fat woman in a pink silk dress.
　　"Password?" she said. "Caput Draconis," said Percy, and the portrait swung forward to reveal a round hole in the wall. They all scrambled through it -- Neville needed a leg up -- and found themselves in the Gryffindor common room, a cozy, round room full of squashy armchairs.
　　Percy directed the girls through one door to their dormitory and the boys through another. At the top of a spiral staircase -- they were obviously in one of the towers -- they found their beds at last: five four-posters hung with deep red, velvet curtains. Their trunks had already been brought up. Too tired to talk much, they pulled on their pajamas and fell into bed.
　　" Great food, isn't it?" Ron muttered to Harry through the hangings. "Get off, Scabbers! He's chewing my sheets."
　　Harry was going to ask Ron if he'd had any of the treacle tart, but he fell asleep almost at once.
　　Perhaps Harry had eaten a bit too much, because he had a very strange dream. He was wearing Professor Quirrell's turban, which kept talking to him, telling him he must transfer to Slytherin at once, because it was his destiny. Harry told the turban he didn't want to be in Slytherin; it got heavier and heavier; he tried to pull it off but it tightened painfully -- and there was Malfoy, laughing at him as he struggled with it -then Malfoy turned into the hook-nosed teacher, Snape, whose laugh became high and cold -- there was a burst of green light and Harry woke, sweating and shaking.
　　He rolled over and fell asleep again, and when he woke next day, he didn't remember the dream at all.
Data Structures and Algorithms: Table of Contents
Data Structures and Algorithms
Alfred V. Aho, Bell Laboratories, Murray Hill, New
Jersey
John E. Hopcroft, Cornell University, Ithaca, New York
Jeffrey D. Ullman, Stanford University, Stanford,
California
PREFACE
Chapter 1 Design and Analysis of Algorithms
Chapter 2 Basic Data Types
Chapter 3 Trees
Chapter 4 Basic Operations on Sets
Chapter 5 Advanced Set Representation Methods
Chapter 6 Directed Graphs
Chapter 7 Undirected Graphs
Chapter 8 Sorting
Chapter 9 Algorithm Analysis Techniques
Chapter 10 Algorithm Design Techniques
Chapter 11 Data Structures and Algorithms for External Storage
Chapter 12 Memory Management
Bibliography
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/toc.htm [1.7.2001 18:57:37]
Preface
Preface
This book presents the data structures and algorithms that underpin much of today's
computer programming. The basis of this book is the material contained in the first
six chapters of our earlier work, The Design and Analysis of Computer Algorithms.
We have expanded that coverage and have added material on algorithms for external
storage and memory management. As a consequence, this book should be suitable as
a text for a first course on data structures and algorithms. The only prerequisite we
assume is familiarity with some high-level programming language such as Pascal.
We have attempted to cover data structures and algorithms in the broader context
of solving problems using computers. We use abstract data types informally in the
description and implementation of algorithms. Although abstract data types are only
starting to appear in widely available programming languages, we feel they are a
useful tool in designing programs, no matter what the language.
We also introduce the ideas of step counting and time complexity as an integral
part of the problem solving process. This decision reflects our longheld belief that
programmers are going to continue to tackle problems of progressively larger size as
machines get faster, and that consequently the time complexity of algorithms will
become of even greater importance, rather than of less importance, as new
generations of hardware become available.
The Presentation of Algorithms
We have used the conventions of Pascal to describe our algorithms and data
structures primarily because Pascal is so widely known. Initially we present several
of our algorithms both abstractly and as Pascal programs, because we feel it is
important to run the gamut of the problem solving process from problem formulation
to a running program. The algorithms we present, however, can be readily
implemented in any high-level programming language.
Use of the Book
Chapter 1 contains introductory remarks, including an explanation of our view of the
problem-to-program process and the role of abstract data types in that process. Also
appearing is an introduction to step counting and "big-oh" and "big-omega" notation.
Chapter 2 introduces the traditional list, stack and queue structures, and the
mapping, which is an abstract data type based on the mathematical notion of a
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/preface.htm (1 of 3) [1.7.2001 18:57:42]
Preface
function. The third chapter introduces trees and the basic data structures that can be
used to support various operations on trees efficiently.
Chapters 4 and 5 introduce a number of important abstract data types that are
based on the mathematical model of a set. Dictionaries and priority queues are
covered in depth. Standard implementations for these concepts, including hash
tables, binary search trees, partially ordered trees, tries, and 2-3 trees are covered,
with the more advanced material clustered in Chapter 5.
Chapters 6 and 7 cover graphs, with directed graphs in Chapter 6 and undirected
graphs in 7. These chapters begin a section of the book devoted more to issues of
algorithms than data structures, although we do discuss the basics of data structures
suitable for representing graphs. A number of important graph algorithms are
presented, including depth-first search, finding minimal spanning trees, shortest
paths, and maximal matchings.
Chapter 8 is devoted to the principal internal sorting algorithms: quicksort,
heapsort, binsort, and the simpler, less efficient methods such as insertion sort. In
this chapter we also cover the linear-time algorithms for finding medians and other
order statistics.
Chapter 9 discusses the asymptotic analysis of recursive procedures, including,
of course, recurrence relations and techniques for solving them.
Chapter 10 outlines the important techniques for designing algorithms, including
divide-and-conquer, dynamic programming, local search algorithms, and various
forms of organized tree searching.
The last two chapters are devoted to external storage organization and memory
management. Chapter 11 covers external sorting and large-scale storage
organization, including B-trees and index structures.
Chapter 12 contains material on memory management, divided into four
subareas, depending on whether allocations involve fixed or varying sized blocks,
and whether the freeing of blocks takes place by explicit program action or implicitly
when garbage collection occurs.
Material from this book has been used by the authors in data structures and
algorithms courses at Columbia, Cornell, and Stanford, at both undergraduate and
graduate levels. For example, a preliminary version of this book was used at Stanford
in a 10-week course on data structures, taught to a population consisting primarily of
Juniors through first-year graduate students. The coverage was limited to Chapters 1-
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/preface.htm (2 of 3) [1.7.2001 18:57:42]
Preface
4, 9, 10, and 12, with parts of 5-7.
Exercises
A number of exercises of varying degrees of difficulty are found at the end of each
chapter. Many of these are fairly straightforward tests of the mastery of the material
of the chapter. Some exercises require more thought, and these have been singly
starred. Doubly starred exercises are harder still, and are suitable for more advanced
courses. The bibliographic notes at the end of each chapter provide references for
additional reading.
Acknowledgments
We wish to acknowledge Bell Laboratories for the use of its excellent UNIX™-
based text preparation and data communication facilities that significantly eased the
preparation of a manuscript by geographically separated authors. Many of our
colleagues have read various portions of the manuscript and have given us valuable
comments and advice. In particular, we would like to thank Ed Beckham, Jon
Bentley, Kenneth Chu, Janet Coursey, Hank Cox, Neil Immerman, Brian Kernighan,
Steve Mahaney, Craig McMurray, Alberto Mendelzon, Alistair Moffat, Jeff
Naughton, Kerry Nemovicher, Paul Niamkey, Yoshio Ohno, Rob Pike, Chris Rouen,
Maurice Schlumberger, Stanley Selkow, Chengya Shih, Bob Tarjan, W. Van Snyder,
Peter Weinberger, and Anthony Yeracaris for helpful suggestions. Finally, we would
like to give our warmest thanks to Mrs. Claire Metzger for her expert assistance in
helping prepare the manuscript for typesetting.
A.V.A.
J.E.H.
J.D.U.
Table of Contents Go to Chapter 1
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/preface.htm (3 of 3) [1.7.2001 18:57:42]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
Design and Analysis of Algorithms
There are many steps involved in writing a computer program to solve a given problem.
The steps go from problem formulation and specification, to design of the solution, to
implementation, testing and documentation, and finally to evaluation of the solution. This
chapter outlines our approach to these steps. Subsequent chapters discuss the algorithms
and data structures that are the building blocks of most computer programs.
1.1 From Problems to Programs
Half the battle is knowing what problem to solve. When initially approached, most
problems have no simple, precise specification. In fact, certain problems, such as creating a
"gourmet" recipe or preserving world peace, may be impossible to formulate in terms that
admit of a computer solution. Even if we suspect our problem can be solved on a computer,
there is usually considerable latitude in several problem parameters. Often it is only by
experimentation that reasonable values for these parameters can be found.
If certain aspects of a problem can be expressed in terms of a formal model, it is usually
beneficial to do so, for once a problem is formalized, we can look for solutions in terms of
a precise model and determine whether a program already exists to solve that problem.
Even if there is no existing program, at least we can discover what is known about this
model and use the properties of the model to help construct a good solution.
Almost any branch of mathematics or science can be called into service to help model
some problem domain. Problems essentially numerical in nature can be modeled by such
common mathematical concepts as simultaneous linear equations (e.g., finding currents in
electrical circuits, or finding stresses in frames made of connected beams) or differential
equations (e.g., predicting population growth or the rate at which chemicals will react).
Symbol and text processing problems can be modeled by character strings and formal
grammars. Problems of this nature include compilation (the translation of programs written
in a programming language into machine language) and information retrieval tasks such as
recognizing particular words in lists of titles owned by a library.
Algorithms
Once we have a suitable mathematical model for our problem, we can attempt to find a
solution in terms of that model. Our initial goal is to find a solution in the form of an
algorithm, which is a finite sequence of instructions, each of which has a clear meaning and
can be performed with a finite amount of effort in a finite length of time. An integer
assignment statement such as x := y + z is an example of an instruction that can be executed
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (1 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
in a finite amount of effort. In an algorithm instructions can be executed any number of
times, provided the instructions themselves indicate the repetition. However, we require
that, no matter what the input values may be, an algorithm terminate after executing a finite
number of instructions. Thus, a program is an algorithm as long as it never enters an
infinite loop on any input.
There is one aspect of this definition of an algorithm that needs some clarification. We
said each instruction of an algorithm must have a "clear meaning" and must be executable
with a "finite amount of effort." Now what is clear to one person may not be clear to
another, and it is often difficult to prove rigorously that an instruction can be carried out in
a finite amount of time. It is often difficult as well to prove that on any input, a sequence of
instructions terminates, even if we understand clearly what each instruction means. By
argument and counterargument, however, agreement can usually be reached as to whether a
sequence of instructions constitutes an algorithm. The burden of proof lies with the person
claiming to have an algorithm. In Section 1.5 we discuss how to estimate the running time
of common programming language constructs that can be shown to require a finite amount
of time for their execution.
In addition to using Pascal programs as algorithms, we shall often present algorithms
using a pseudo-language that is a combination of the constructs of a programming language
together with informal English statements. We shall use Pascal as the programming
language, but almost any common programming language could be used in place of Pascal
for the algorithms we shall discuss. The following example illustrates many of the steps in
our approach to writing a computer program.
Example 1.1. A mathematical model can be used to help design a traffic light for a
complicated intersection of roads. To construct the pattern of lights, we shall create a
program that takes as input a set of permitted turns at an intersection (continuing straight on
a road is a "turn") and partitions this set into as few groups as possible such that all turns in
a group are simultaneously permissible without collisions. We shall then associate a phase
of the traffic light with each group in the partition. By finding a partition with the smallest
number of groups, we can construct a traffic light with the smallest number of phases.
For example, the intersection shown in Fig. 1.1 occurs by a watering hole called JoJo's
near Princeton University, and it has been known to cause some navigational difficulty,
especially on the return trip. Roads C and E are oneway, the others two way. There are 13
turns one might make at this intersection. Some pairs of turns, like AB (from A to B) and
EC, can be carried out simultaneously, while others, like AD and EB, cause lines of traffic
to cross and therefore cannot be carried out simultaneously. The light at the intersection
must permit turns in such an order that AD and EB are never permitted at the same time,
while the light might permit AB and EC to be made simultaneously.
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (2 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
Fig. 1.1. An intersection.
We can model this problem with a mathematical structure known as a graph. A graph
consists of a set of points called vertices, and lines connecting the points, called edges. For
the traffic intersection problem we can draw a graph whose vertices represent turns and
whose edges connect pairs of vertices whose turns cannot be performed simultaneously.
For the intersection of Fig. 1.1, this graph is shown in Fig. 1.2, and in Fig. 1.3 we see
another representation of this graph as a table with a 1 in row i and column j whenever
there is an edge between vertices i and j.
The graph can aid us in solving the traffic light design problem. A coloring of a graph is
an assignment of a color to each vertex of the graph so that no two vertices connected by an
edge have the same color. It is not hard to see that our problem is one of coloring the graph
of incompatible turns using as few colors as possible.
The problem of coloring graphs has been studied for many decades, and the theory of
algorithms tells us a lot about this problem. Unfortunately, coloring an arbitrary graph with
as few colors as possible is one of a large class of problems called "NP-complete
problems," for which all known solutions are essentially of the type "try all possibilities."
In the case of the coloring problem, "try all possibilities" means to try all assignments of
colors to vertices using at first one color, then two colors, then three, and so on, until a legal
coloring is found. With care, we can be a little speedier than this, but it is generally
believed that no algorithm to solve this problem can be substantially more efficient than
this most obvious approach.
We are now confronted with the possibility that finding an optimal solution for the
problem at hand is computationally very expensive. We can adopt
Fig. 1.2. Graph showing incompatible turns.
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (3 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
Fig. 1.3. Table of incompatible turns.
one of three approaches. If the graph is small, we might attempt to find an optimal solution
exhaustively, trying all possibilities. This approach, however, becomes prohibitively
expensive for large graphs, no matter how efficient we try to make the program. A second
approach would be to look for additional information about the problem at hand. It may
turn out that the graph has some special properties, which make it unnecessary to try all
possibilities in finding an optimal solution. The third approach is to change the problem a
little and look for a good but not necessarily optimal solution. We might be happy with a
solution that gets close to the minimum number of colors on small graphs, and works
quickly, since most intersections are not even as complex as Fig. 1.1. An algorithm that
quickly produces good but not necessarily optimal solutions is called a heuristic.
One reasonable heuristic for graph coloring is the following "greedy" algorithm. Initially
we try to color as many vertices as possible with the first color, then as many as possible of
the uncolored vertices with the second color, and so on. To color vertices with a new color,
we perform the following steps.
1. Select some uncolored vertex and color it with the new color.
2. Scan the list of uncolored vertices. For each uncolored vertex, determine whether it
has an edge to any vertex already colored with the new color. If there is no such
edge, color the present vertex with the new color.
This approach is called "greedy" because it colors a vertex whenever it can, without
considering the potential drawbacks inherent in making such a move. There are situations
where we could color more vertices with one color if we were less "greedy" and skipped
some vertex we could legally color. For example, consider the graph of Fig. 1.4, where
having colored vertex 1 red, we can color vertices 3 and 4 red also, provided we do not
color 2 first. The greedy algorithm would tell us to color 1 and 2 red, assuming we
considered vertices in numerical order.
Fig. 1.4. A graph.
As an example of the greedy approach applied to Fig. 1.2, suppose we start by coloring
AB blue. We can color AC, AD, and BA blue, because none of these four vertices has an
edge in common. We cannot color BC blue because there is an edge between AB and BC.
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (4 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
Similarly, we cannot color BD, DA, or DB blue because each of these vertices is connected
by an edge to one or more vertices already colored blue. However, we can color DC blue.
Then EA, EB, and EC cannot be colored blue, but ED can.
Now we start a second color, say by coloring BC red. BD can be colored red, but DA
cannot, because of the edge between BD and DA. Similarly, DB cannot be colored red, and
DC is already blue, but EA can be colored red. Each other uncolored vertex has an edge to a
red vertex, so no other vertex can be colored red.
The remaining uncolored vertices are DA, DB, EB, and EC. If we color DA green, then
DB can be colored green, but EB and EC cannot. These two may be colored with a fourth
color, say yellow. The colors are summarized in Fig. 1.5. The "extra" turns are determined
by the greedy approach to be compatible with the turns already given that color, as well as
with each other. When the traffic light allows turns of one color, it can also allow the extra
turns safely.
Fig. 1.5. A coloring of the graph of Fig. 1.2.
The greedy approach does not always use the minimum possible number of colors. We
can use the theory of algorithms again to evaluate the goodness of the solution produced. In
graph theory, a k-clique is a set of k vertices, every pair of which is connected by an edge.
Obviously, k colors are needed to color a k-clique, since no two vertices in a clique may be
given the same color.
In the graph of Fig. 1.2 the set of four vertices AC, DA, BD, EB is a 4-clique. Therefore,
no coloring with three or fewer colors exists, and the solution of Fig. 1.5 is optimal in the
sense that it uses the fewest colors possible. In terms of our original problem, no traffic
light for the intersection of Fig. 1.1 can have fewer than four phases.
Therefore, consider a traffic light controller based on Fig. 1.5, where each phase of the
controller corresponds to a color. At each phase the turns indicated by the row of the table
corresponding to that color are permitted, and the other turns are forbidden. This pattern
uses as few phases as possible.
Pseudo-Language and Stepwise Refinement
Once we have an appropriate mathematical model for a problem, we can formulate an
algorithm in terms of that model. The initial versions of the algorithm are often couched in
general statements that will have to be refined subsequently into smaller, more definite
instructions. For example, we described the greedy graph coloring algorithm in terms such
as "select some uncolored vertex." These instructions are, we hope, sufficiently clear that
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (5 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
the reader grasps our intent. To convert such an informal algorithm to a program, however,
we must go through several stages of formalization (called stepwise refinement) until we
arrive at a program the meaning of whose steps are formally defined by a language manual.
Example 1.2. Let us take the greedy algorithm for graph coloring part of the way towards a
Pascal program. In what follows, we assume there is a graph G, some of whose vertices
may be colored. The following program greedy determines a set of vertices called newclr,
all of which can be colored with a new color. The program is called repeatedly, until all
vertices are colored. At a coarse level, we might specify greedy in pseudo-language as in
Fig. 1.6.
procedure greedy ( var G: GRAPH; var newclr: SET );
{ greedy assigns to newclr a set of vertices of G that may be
given the same color }
begin
(1) newclr := Ø; †
(2) for each uncolored vertex v of G do
(3) if v is not adjacent to any vertex in newclr then begin
(4) mark v colored;
(5) add v to newclr
end
end; { greedy }
Fig. 1.6. First refinement of greedy algorithm.
We notice from Fig. 1.6 certain salient features of our pseudo-language. First, we use
boldface lower case keywords corresponding to Pascal reserved words, with the same
meaning as in standard Pascal. Upper case types such as GRAPH and SET‡ are the names
of "abstract data types." They will be defined by Pascal type definitions and the operations
associated with these abstract data types will be defined by Pascal procedures when we
create the final program. We shall discuss abstract data types in more detail in the next two
sections.
The flow-of-control constructs of Pascal, like if, for, and while, are available for pseudolanguage
statements, but conditionals, as in line (3), may be informal statements rather than
Pascal conditional expressions. Note that the assignment at line (1) uses an informal
expression on the right. Also, the for-loop at line (2) iterates over a set.
To be executed, the pseudo-language program of Fig. 1.6 must be refined into a
conventional Pascal program. We shall not proceed all the way to such a program in this
example, but let us give one example of refinement, transforming the if-statement in line
(3) of Fig. 1.6 into more conventional code.
To test whether vertex v is adjacent to some vertex in newclr, we consider each member
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (6 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
w of newclr and examine the graph G to see whether there is an edge between v and w. An
organized way to make this test is to use found, a boolean variable to indicate whether an
edge has been found. We can replace lines (3)-(5) of Fig. 1.6 by the code in Fig. 1.7.
procedure greedy ( var G: GRAPH; var newclr: SET );
begin
(1) newclr : = Ø;
(2) for each uncolored vertex v of G do begin
(3.1) found := false;
(3.2) for each vertex w in newclr do
(3.3) if there is an edge between v and w in G then
(3.4) found := true;
(3.5) if found = false then begin
{ v is adjacent to no vertex in newclr }
(4) mark v colored;
(5) add v to newclr
end
end
end; { greedy }
Fig. 1.7. Refinement of part of Fig. 1.6.
We have now reduced our algorithm to a collection of operations on two sets of vertices.
The outer loop, lines (2)-(5), iterates over the set of uncolored vertices of G. The inner
loop, lines (3.2)-(3.4), iterates over the vertices currently in the set newclr. Line (5) adds
newly colored vertices to newclr.
There are a variety of ways to represent sets in a programming language like Pascal. In
Chapters 4 and 5 we shall study several such representations. In this example we can
simply represent each set of vertices by another abstract data type LIST, which here can be
implemented by a list of integers terminated by a special value null (for which we might
use the value 0). These integers might, for example, be stored in an array, but there are
many other ways to represent LIST's, as we shall see in Chapter 2.
We can now replace the for-statement of line (3.2) in Fig. 1.7 by a loop, where w is
initialized to be the first member of newclr and changed to be the next member, each time
around the loop. We can also perform the same refinement for the for-loop of line (2) in
Fig. 1.6. The revised procedure greedy is shown in Fig. 1.8. There is still more refinement
to be done after Fig. 1.8, but we shall stop here to take stock of what we have done.
procedure greedy ( var G: GRAPH; var newclr: LIST );
{ greedy assigns to newclr those vertices that may be
given the same color }
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (7 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
var
found: boolean;
v, w: integer;
begin
newclr := Ø;
v := first uncolored vertex in G;
while v < > null do begin
found := false;
w := first vertex in newclr;
while w < > null do begin
if there is an edge between v and w in G then
found := true;
w := next vertex in newclr
end;
if found = false do begin
mark v colored;
add v to newclr
end;
v := next uncolored vertex in G
end
end; { greedy }
Fig. 1.8. Refined greedy procedure.
Summary
In Fig. 1.9 we see the programming process as it will be treated in this book. The first stage
is modeling using an appropriate mathematical model such as a graph. At this stage, the
solution to the problem is an algorithm expressed very informally.
At the next stage, the algorithm is written in pseudo-language, that is, a mixture of
Pascal constructs and less formal English statements. To reach that stage, the informal
English is replaced by progressively more detailed sequences of statements, in the process
known as stepwise refinement. At some point the pseudo-language program is sufficiently
detailed that the
Fig. 1.9. The problem solving process.
operations to be performed on the various types of data become fixed. We then create
abstract data types for each type of data (except for the elementary types such as integers,
reals and character strings) by giving a procedure name for each operation and replacing
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (8 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
uses of each operation by an invocation of the corresponding procedure.
In the third stage we choose an implementation for each abstract data type and write the
procedures for the various operations on that type. We also replace any remaining informal
statements in the pseudo-language algorithm by Pascal code. The result is a running
program. After debugging it will be a working program, and we hope that by using the
stepwise development approach outlined in Fig. 1.9, little debugging will be necessary.
1.2 Abstract Data Types
Most of the concepts introduced in the previous section should be familiar ideas from a
beginning course in programming. The one possibly new notion is that of an abstract data
type, and before proceeding it would be useful to discuss the role of abstract data types in
the overall program design process. To begin, it is useful to compare an abstract data type
with the more familiar notion of a procedure.
Procedures, an essential tool in programming, generalize the notion of an operator.
Instead of being limited to the built-in operators of a programming language (addition,
subtraction, etc.), by using procedures a programmer is free to define his own operators and
apply them to operands that need not be basic types. An example of a procedure used in
this way is a matrix multiplication routine.
Another advantage of procedures is that they can be used to encapsulate parts of an
algorithm by localizing in one section of a program all the statements relevant to a certain
aspect of a program. An example of encapsulation is the use of one procedure to read all
input and to check for its validity. The advantage of encapsulation is that we know where to
go to make changes to the encapsulated aspect of the problem. For example, if we decide to
check that inputs are nonnegative, we need to change only a few lines of code, and we
know just where those lines are.
Definition of Abstract Data Type
We can think of an abstract data type (ADT) as a mathematical model with a collection of
operations defined on that model. Sets of integers, together with the operations of union,
intersection, and set difference, form a simple example of an ADT. In an ADT, the
operations can take as operands not only instances of the ADT being defined but other
types of operands, e.g., integers or instances of another ADT, and the result of an operation
can be other than an instance of that ADT. However, we assume that at least one operand,
or the result, of any operation is of the ADT in question.
The two properties of procedures mentioned above -- generalization and encapsulation --
apply equally well to abstract data types. ADT's are generalizations of primitive data types
(integer, real, and so on), just as procedures are generalizations of primitive operations (+, -
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (9 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
, and so on). The ADT encapsulates a data type in the sense that the definition of the type
and all operations on that type can be localized to one section of the program. If we wish to
change the implementation of an ADT, we know where to look, and by revising one small
section we can be sure that there is no subtlety elsewhere in the program that will cause
errors concerning this data type. Moreover, outside the section in which the ADT's
operations are defined, we can treat the ADT as a primitive type; we have no concern with
the underlying implementation. One pitfall is that certain operations may involve more than
one ADT, and references to these operations must appear in the sections for both ADT's.
To illustrate the basic ideas, consider the procedure greedy of the previous section
which, in Fig. 1.8, was implemented using primitive operations on an abstract data type
LIST (of integers). The operations performed on the LIST newclr were:
1. make a list empty,
2. get the first member of the list and return null if the list is empty,
3. get the next member of the list and return null if there is no next member, and
4. insert an integer into the list.
There are many data structures that can be used to implement such lists efficiently, and
we shall consider the subject in depth in Chapter 2. In Fig. 1.8, if we replace these
operations by the statements
1. MAKENULL(newclr);
2. w := FIRST(newclr);
3. w := NEXT(newclr);
4. INSERT(v, newclr);
then we see an important aspect of abstract data types. We can implement a type any way
we like, and the programs, such as Fig. 1.8, that use objects of that type do not change; only
the procedures implementing the operations on the type need to change.
Turning to the abstract data type GRAPH we see need for the following operations:
1. get the first uncolored vertex,
2. test whether there is an edge between two vertices,
3. mark a vertex colored, and
4. get the next uncolored vertex.
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (10 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
There are clearly other operations needed outside the procedure greedy, such as inserting
vertices and edges into the graph and making all vertices uncolored. There are many data
structures that can be used to support graphs with these operations, and we shall study the
subject of graphs in Chapters 6 and 7.
It should be emphasized that there is no limit to the number of operations that can be
applied to instances of a given mathematical model. Each set of operations defines a
distinct ADT. Some examples of operations that might be defined on an abstract data type
SET are:
1. MAKENULL(A). This procedure makes the null set be the value for set A.
2. UNION(A, B, C). This procedure takes two set-valued arguments A and B, and
assigns the union of A and B to be the value of set C.
3. SIZE(A). This function takes a set-valued argument A and returns an object of type
integer whose value is the number of elements in the set A.
An implementation of an ADT is a translation, into statements of a programming
language, of the declaration that defines a variable to be of that abstract data type, plus a
procedure in that language for each operation of the ADT. An implementation chooses a
data structure to represent the ADT; each data structure is built up from the basic data
types of the underlying programming language using the available data structuring
facilities. Arrays and record structures are two important data structuring facilities that are
available in Pascal. For example, one possible implementation for variable S of type SET
would be an array that contained the members of S.
One important reason for defining two ADT's to be different if they have the same
underlying model but different operations is that the appropriateness of an implementation
depends very much on the operations to be performed. Much of this book is devoted to
examining some basic mathematical models such as sets and graphs, and developing the
preferred implementations for various collections of operations.
Ideally, we would like to write our programs in languages whose primitive data types
and operations are much closer to the models and operations of our ADT's. In many ways
Pascal is not well suited to the implementation of various common ADT's but none of the
programming languages in which ADT's can be declared more directly is as well known.
See the bibliographic notes for information about some of these languages.
1.3 Data Types, Data Structures and Abstract
Data Types
Although the terms "data type" (or just "type"), "data structure" and "abstract data type"
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (11 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
sound alike, they have different meanings. In a programming language, the data type of a
variable is the set of values that the variable may assume. For example, a variable of type
boolean can assume either the value true or the value false, but no other value. The basic
data types vary from language to language; in Pascal they are integer, real, boolean, and
character. The rules for constructing composite data types out of basic ones also vary from
language to language; we shall mention how Pascal builds such types momentarily.
An abstract data type is a mathematical model, together with various operations defined
on the model. As we have indicated, we shall design algorithms in terms of ADT's, but to
implement an algorithm in a given programming language we must find some way of
representing the ADT's in terms of the data types and operators supported by the
programming language itself. To represent the mathematical model underlying an ADT we
use data structures, which are collections of variables, possibly of several different data
types, connected in various ways.
The cell is the basic building block of data structures. We can picture a cell as a box that
is capable of holding a value drawn from some basic or composite data type. Data
structures are created by giving names to aggregates of cells and (optionally) interpreting
the values of some cells as representing connections (e.g., pointers) among cells.
The simplest aggregating mechanism in Pascal and most other programming languages
is the (one-dimensional) array, which is a sequence of cells of a given type, which we shall
often refer to as the celltype. We can think of an array as a mapping from an index set (such
as the integers 1, 2, . . . , n) into the celltype. A cell within an array can be referenced by
giving the array name together with a value from the index set of the array. In Pascal the
index set may be an enumerated type, such as (north, east, south, west), or a subrange type,
such as 1..10. The values in the cells of an array can be of any one type. Thus, the
declaration
name: array[indextype] of celltype;
declares name to be a sequence of cells, one for each value of type indextype; the contents
of the cells can be any member of type celltype.
Incidentally, Pascal is somewhat unusual in its richness of index types. Many languages
allow only subrange types (finite sets of consecutive integers) as index types. For example,
to index an array by letters in Fortran, one must simulate the effect by using integer indices,
such as by using index 1 to stand for 'A', 2 to stand for 'B', and so on.
Another common mechanism for grouping cells in programming languages is the record
structure. A record is a cell that is made up of a collection of cells, called fields, of possibly
dissimilar types. Records are often grouped into arrays; the type defined by the aggregation
of the fields of a record becomes the "celltype" of the array. For example, the Pascal
declaration
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (12 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
var
reclist: array[l..4] of record
data: real;
next: integer
end
declares reclist to be a four-element array, whose cells are records with two fields, data and
next.
A third grouping method found in Pascal and some other languages is the file. The file,
like the one-dimensional array, is a sequence of values of some particular type. However, a
file has no index type; elements can be accessed only in the order of their appearance in the
file. In contrast, both the array and the record are "random-access" structures, meaning that
the time needed to access a component of an array or record is independent of the value of
the array index or field selector. The compensating benefit of grouping by file, rather than
by array, is that the number of elements in a file can be time-varying and unlimited.
Pointers and Cursors
In addition to the cell-grouping features of a programming language, we can represent
relationships between cells using pointers and cursors. A pointer is a cell whose value
indicates another cell. When we draw pictures of data structures, we indicate the fact that
cell A is a pointer to cell B by drawing an arrow from A to B.
In Pascal, we can create a pointer variable ptr that will point to cells of a given type, say
celltype, by the declaration
var
ptr: ­ celltype
A postfix up-arrow is used in Pascal as the dereferencing operator, so the expression ptr­
denotes the value (of type celltype) in the cell pointed to by ptr.
A cursor is an integer-valued cell, used as a pointer to an array. As a method of
connection, the cursor is essentially the same as a pointer, but a cursor can be used in
languages like Fortran that do not have explicit pointer types as Pascal does. By treating a
cell of type integer as an index value for some array, we effectively make that cell point to
one cell of the array. This technique, unfortunately, works only when cells of arrays are
pointed to; there is no reasonable way to interpret an integer as a "pointer" to a cell that is
not part of an array.
We shall draw an arrow from a cursor cell to the cell it "points to." Sometimes, we shall
also show the integer in the cursor cell, to remind us that it is not a true pointer. The reader
should observe that the Pascal pointer mechanism is such that cells in arrays can only be
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (13 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
"pointed to" by cursors, never by true pointers. Other languages, like PL/I or C, allow
components of arrays to be pointed to by either cursors or true pointers, while in Fortran or
Algol, there being no pointer type, only cursors can be used.
Example 1.3. In Fig. 1.10 we see a two-part data structure that consists of a chain of cells
containing cursors to the array reclist defined above. The purpose of the field next in reclist
is to point to another record in the array. For example, reclist[4].next is 1, so record 4 is
followed by record 1. Assuming record 4 is first, the next field of reclist orders the records
4, 1, 3, 2. Note that the next field is 0 in record 2, indicating that there is no following
record. It is a useful convention, one we shall adopt in this book, to use 0 as a "NIL
pointer," when cursors are being used. This idea is sound only if we also make the
convention that arrays to which cursors "point" must be indexed starting at 1, never at 0.
Fig. 1.10. Example of a data structure.
The cells in the chain of records in Fig. 1.10 are of the type
type
recordtype = record
cursor: integer;
ptr: ­ recordtype
end
The chain is pointed to by a variable named header, which is of type ­ record-type; header
points to an anonymous record of type recordtype.† That record has a value 4 in its cursor
field; we regard this 4 as an index into the array reclist. The record has a true pointer in
field ptr to another anonymous record. The record pointed to has an index in its cursor field
indicating position 2 of reclist; it also has a nil pointer in its ptr field.
1.4 The Running Time of a Program
When solving a problem we are faced frequently with a choice among algorithms. On what
basis should we choose? There are two often contradictory goals.
1. We would like an algorithm that is easy to understand, code, and debug.
2. We would like an algorithm that makes efficient use of the computer's resources,
especially, one that runs as fast as possible.
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (14 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
When we are writing a program to be used once or a few times, goal (1) is most
important. The cost of the programmer's time will most likely exceed by far the cost of
running the program, so the cost to optimize is the cost of writing the program. When
presented with a problem whose solution is to be used many times, the cost of running the
program may far exceed the cost of writing it, especially, if many of the program runs are
given large amounts of input. Then it is financially sound to implement a fairly complicated
algorithm, provided that the resulting program will run significantly faster than a more
obvious program. Even in these situations it may be wise first to implement a simple
algorithm, to determine the actual benefit to be had by writing a more complicated
program. In building a complex system it is often desirable to implement a simple
prototype on which measurements and simulations can be performed, before committing
oneself to the final design. It follows that programmers must not only be aware of ways of
making programs run fast, but must know when to apply these techniques and when not to
bother.
Measuring the Running Time of a Program
The running time of a program depends on factors such as:
1. the input to the program,
2. the quality of code generated by the compiler used to create the object program,
3. the nature and speed of the instructions on the machine used to execute the program,
and
4. the time complexity of the algorithm underlying the program.
The fact that running time depends on the input tells us that the running time of a
program should be defined as a function of the input. Often, the running time depends not
on the exact input but only on the "size" of the input. A good example is the process known
as sorting, which we shall discuss in Chapter 8. In a sorting problem, we are given as input
a list of items to be sorted, and we are to produce as output the same items, but smallest (or
largest) first. For example, given 2, 1, 3, 1, 5, 8 as input we might wish to produce 1, 1, 2,
3, 5, 8 as output. The latter list is said to be sorted smallest first. The natural size measure
for inputs to a sorting program is the number of items to be sorted, or in other words, the
length of the input list. In general, the length of the input is an appropriate size measure,
and we shall assume that measure of size unless we specifically state otherwise.
It is customary, then, to talk of T(n), the running time of a program on inputs of size n.
For example, some program may have a running time T(n) = cn2, where c is a constant. The
units of T(n) will be left unspecified, but we can think of T(n) as being the number of
instructions executed on an idealized computer.
For many programs, the running time is really a function of the particular input, and not
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (15 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
just of the input size. In that case we define T(n) to be the worst case running time, that is,
the maximum, over all inputs of size n, of the running time on that input. We also consider
Tavg(n), the average, over all inputs of size n, of the running time on that input. While
Tavg(n) appears a fairer measure, it is often fallacious to assume that all inputs are equally
likely. In practice, the average running time is often much harder to determine than the
worst-case running time, both because the analysis becomes mathematically intractable and
because the notion of "average" input frequently has no obvious meaning. Thus, we shall
use worst-case running time as the principal measure of time complexity, although we shall
mention average-case complexity wherever we can do so meaningfully.
Now let us consider remarks (2) and (3) above: that the running time of a program
depends on the compiler used to compile the program and the machine used to execute it.
These facts imply that we cannot express the running time T(n) in standard time units such
as seconds. Rather, we can only make remarks like "the running time of such-and-such an
algorithm is proportional to n2." The constant of proportionality will remain unspecified
since it depends so heavily on the compiler, the machine, and other factors.
Big-Oh and Big-Omega Notation
To talk about growth rates of functions we use what is known as "big-oh" notation. For
example, when we say the running time T(n) of some program is O(n2), read "big oh of n
squared" or just "oh of n squared," we mean that there are positive constants c and n0 such
that for n equal to or greater than n0, we have T(n) £ cn2.
Example 1.4. Suppose T(0) = 1, T(1) = 4, and in general T(n) = (n+l)2. Then we see that
T(n) is O(n2), as we may let n0 = 1 and c = 4. That is, for n ³ 1, we have (n + 1)2 £ 4n2, as
the reader may prove easily. Note that we cannot let n0 = 0, because T(0) = 1 is not less
than c02 = 0 for any constant c.
In what follows, we assume all running-time functions are defined on the nonnegative
integers, and their values are always nonnegative, although not necessarily integers. We say
that T(n) is O(f(n)) if there are constants c and n0 such that T(n) £ cf(n) whenever n ³ n0. A
program whose running time is O(f (n)) is said to have growth rate f(n).
Example 1.5. The function T(n)= 3n3 + 2n2 is O(n3). To see this, let n0 = 0 and c = 5.
Then, the reader may show that for n ³ 0, 3n3 + 2n2 £ 5n3. We could also say that this T(n)
is O(n4), but this would be a weaker statement than saying it is O(n3).
As another example, let us prove that the function 3n is not O (2n). Suppose that there
were constants n0 and c such that for all n ³ n0, we had 3n £ c2n. Then c ³ (3/2)n for any n
³ n0. But (3/2)n gets arbitrarily large as n gets large, so no constant c can exceed (3/2)n for
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (16 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
all n.
When we say T(n) is O(f(n)), we know that f(n) is an upper bound on the growth rate of
T(n). To specify a lower bound on the growth rate of T(n) we can use the notation T(n) is
W(g(n)), read "big omega of g(n)" or just "omega of g(n)," to mean that there exists a
positive constant c such that T(n) ³ cg(n) infinitely often (for an infinite number of values
of n).†
Example 1.6. To verify that the function T(n)= n3 + 2n2 is W(n3), let c = 1. Then T(n) ³ cn3
for n = 0, 1, . . ..
For another example, let T(n) = n for odd n ³ 1 and T(n) = n2/100 for even n ³ 0. To
verify that T(n) is W (n2), let c = 1/100 and consider the infinite set of n's: n = 0, 2, 4, 6, . . ..
The Tyranny of Growth Rate
We shall assume that programs can be evaluated by comparing their running-time
functions, with constants of proportionality neglected. Under this assumption a program
with running time O(n2) is better than one with running time O(n3), for example. Besides
constant factors due to the compiler and machine, however, there is a constant factor due to
the nature of the program itself. It is possible, for example, that with a particular compilermachine
combination, the first program takes 100n2 milliseconds, while the second takes
5n3 milliseconds. Might not the 5n3 program be better than the 100n2 program?
The answer to this question depends on the sizes of inputs the programs are expected to
process. For inputs of size n < 20, the program with running time 5n3 will be faster than the
one with running time 100n2. Therefore, if the program is to be run mainly on inputs of
small size, we would indeed prefer the program whose running time was O(n3). However,
as n gets large, the ratio of the running times, which is 5n3/100n2 = n/20, gets arbitrarily
large. Thus, as the size of the input increases, the O(n3) program will take significantly
more time than the O(n2) program. If there are even a few large inputs in the mix of
problems these two programs are designed to solve, we can be much better off with the
program whose running time has the lower growth rate.
Another reason for at least considering programs whose growth rates are as low as
possible is that the growth rate ultimately determines how big a problem we can solve on a
computer. Put another way, as computers get faster, our desire to solve larger problems on
them continues to increase. However, unless a program has a low growth rate such as O(n)
or O(nlogn), a modest increase in computer speed makes very little difference in the size of
the largest problem we can solve in a fixed amount of time.
Example 1.7. In Fig. 1.11 we see the running times of four programs with different time
complexities, measured in seconds, for a particular compiler-machine combination.
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (17 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
Suppose we can afford 1000 seconds, or about 17 minutes, to solve a given problem. How
large a problem can we solve? In 103 seconds, each of the four algorithms can solve
roughly the same size problem, as shown in the second column of Fig. 1.12.
Fig. 1.11. Running times of four programs.
Suppose that we now buy a machine that runs ten times faster at no additional cost.
Then for the same cost we can spend 104 seconds on a problem where we spent 103
seconds before. The maximum size problem we can now solve using each of the four
programs is shown in the third column of Fig. 1.12, and the ratio of the third and second
columns is shown in the fourth column. We observe that a 1000% improvement in
computer speed yields only a 30% increase in the size of problem we can solve if we use
the O(2n) program. Additional factors of ten speedup in the computer yield an even smaller
percentage increase in problem size. In effect, the O(2n) program can solve only small
problems no matter how fast the underlying computer.
Fig. 1.12. Effect of a ten-fold speedup in computation time.
In the third column of Fig. 1.12 we see the clear superiority of the O(n) program; it
returns a 1000% increase in problem size for a 1000% increase in computer speed. We see
that the O(n3) and O(n2) programs return, respectively, 230% and 320% increases in
problem size for 1000% increases in speed. These ratios will be maintained for additional
increases in speed.
As long as the need for solving progressively larger problems exists, we are led to an
almost paradoxical conclusion. As computation becomes cheaper and machines become
faster, as will most surely continue to happen, our desire to solve larger and more complex
problems will continue to increase. Thus, the discovery and use of efficient algorithms,
those whose growth rates are low, becomes more rather than less important.
A Few Grains of Salt
We wish to re-emphasize that the growth rate of the worst case running time is not the sole,
or necessarily even the most important, criterion for evaluating an algorithm or program.
Let us review some conditions under which the running time of a program can be
overlooked in favor of other issues.
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (18 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
1. If a program is to be used only a few times, then the cost of writing and debugging
dominate the overall cost, so the actual running time rarely affects the total cost. In
this case, choose the algorithm that is easiest to implement correctly.
2. If a program is to be run only on "small" inputs, the growth rate of the running time
may be less important than the constant factor in the formula for running time. What
is a "small" input depends on the exact running times of the competing algorithms.
There are some algorithms, such as the integer multiplication algorithm due to
Schonhage and Strassen [1971], that are asymptotically the most efficient known for
their problem, but have never been used in practice even on the largest problems,
because the constant of proportionality is so large in comparison to other simpler,
less "efficient" algorithms.
3. A complicated but efficient algorithm may not be desirable because a person other
than the writer may have to maintain the program later. It is hoped that by making
the principal techniques of efficient algorithm design widely known, more complex
algorithms may be used freely, but we must consider the possibility of an entire
program becoming useless because no one can understand its subtle but efficient
algorithms.
4. There are a few examples where efficient algorithms use too much space to be
implemented without using slow secondary storage, which may more than negate
the efficiency.
5. In numerical algorithms, accuracy and stability are just as important as efficiency.
1.5 Calculating the Running Time of a
Program
Determining, even to within a constant factor, the running time of an arbitrary program can
be a complex mathematical problem. In practice, however, determining the running time of
a program to within a constant factor is usually not that difficult; a few basic principles
suffice. Before presenting these principles, it is important that we learn how to add and
multiply in "big oh" notation.
Suppose that T1(n) and T2(n) are the running times of two program fragments P1 and P2,
and that T1(n) is O(f(n)) and T2(n) is O(g(n)). Then T1(n)+T2(n), the running time of P1
followed by P2, is O(max(f(n),g(n))). To see why, observe that for some constants c1, c2,
n1, and n2, if n ³ n1 then T1(n) £ c1f(n), and if n ³ n2 then T2(n) £ c2g(n). Let n0 = max(n1,
n2). If n ³ n0, then T1(n) + T2(n) £ c1f(n) + c2g(n). From this we conclude that if n ³ n0,
then T1(n) + T2(n) £ (c1 + c2)max(f(n), g(n)). Therefore, the combined running time T1(n) +
T2(n) is O (max(f (n), g (n))).
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (19 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
Example 1.8. The rule for sums given above can be used to calculate the running time of a
sequence of program steps, where each step may be an arbitrary program fragment with
loops and branches. Suppose that we have three steps whose running times are,
respectively, O(n2), O(n3) and O(n log n). Then the running time of the first two steps
executed sequentially is O(max(n2, n3)) which is O(n3). The running time of all three
together is O(max(n3, n log n)) which is O(n3).
In general, the running time of a fixed sequence of steps is, to within a constant factor,
the running time of the step with the largest running time. In rare circumstances there will
be two or more steps whose running times are incommensurate (neither is larger than the
other, nor are they equal). For example, we could have steps of running times O(f (n)) and
O(g (n)), where
In such cases the sum rule must be applied directly; the running time is O(max(f(n), g(n))),
that is, n4 if n is even and n3 if n is odd.
Another useful observation about the sum rule is that if g(n) £ f(n) for all n above some
constant n0, then O(f(n) + g(n)) is the same as O(f(n)). For example, O(n2+n) is the same as
O(n2).
The rule for products is the following. If T1(n) and T2(n) are O(f(n)) and O(g(n)),
respectively, then T1(n)T2(n) is O(f(n)g(n)). The reader should prove this fact using the
same ideas as in the proof of the sum rule. It follows from the product rule that O(cf(n))
means the same thing as O(f(n)) if c is any positive constant. For example, O(n2/2) is the
same as O(n2).
Before proceeding to the general rules for analyzing the running times of programs, let
us take a simple example to get an overview of the process.
Example 1.9. Consider the sorting program bubble of Fig. 1.13, which sorts an array of
integers into increasing order. The net effect of each pass of the inner loop of statements (3)-
(6) is to "bubble" the smallest element toward the front of the array.
procedure bubble ( var A: array [1..n] of integer );
{ bubble sorts array A into increasing order }
var
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (20 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
i, j, temp: integer;
begin
(1) for i := 1 to n-1 do
(2) for j := n downto i+1 do
(3) if A[j-1] > A[j] then begin
{ swap A[j - 1] and A[j] }
(4) temp := A[j-1];
(5) A[j-1] := A[j];
(6) AI> [j] := temp
end
end; { bubble }
Fig. 1.13. Bubble sort.
The number n of elements to be sorted is the appropriate measure of input size. The first
observation we make is that each assignment statement takes some constant amount of
time, independent of the input size. That is to say, statements (4), (5) and (6) each take O(1)
time. Note that O(1) is "big oh" notation for "some constant amount." By the sum rule, the
combined running time of this group of statements is O(max(1, 1, 1)) = O(1).
Now we must take into account the conditional and looping statements. The if- and forstatements
are nested within one another, so we may work from the inside out to get the
running time of the conditional group and each loop. For the if-statement, testing the
condition requires O(1) time. We don't know whether the body of the if-statement (lines (4)-
(6)) will be executed. Since we are looking for the worst-case running time, we assume the
worst and suppose that it will. Thus, the if-group of statements (3)-(6) takes O(1) time.
Proceeding outward, we come to the for-loop of lines (2)-(6). The general rule for a loop
is that the running time is the sum, over each iteration of the loop, of the time spent
executing the loop body for that iteration. We must, however, charge at least O(1) for each
iteration to account for incrementing the index, for testing to see whether the limit has been
reached, and for jumping back to the beginning of the loop. For lines (2)-(6) the loop body
takes O(1) time for each iteration. The number of iterations of the loop is n-i, so by the
product rule, the time spent in the loop of lines (2)-(6) is O((n-i) X 1) which is O(n-i).
Now let us progress to the outer loop, which contains all the executable statements of
the program. Statement (1) is executed n - 1 times, so the total running time of the program
is bounded above by some constant times
which is O(n2). The program of Fig. 1.13, therefore, takes time proportional to the square
of the number of items to be sorted. In Chapter 8, we shall give sorting programs whose
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (21 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
running time is O(nlogn), which is considerably smaller, since for large n, logn† is very
much smaller than n.
Before proceeding to some general analysis rules, let us remember that determining a
precise upper bound on the running time of programs is sometimes simple, but at other
times it can be a deep intellectual challenge. There are no complete sets of rules for
analyzing programs. We can only give the reader some hints and illustrate some of the
subtler points by examples throughout this book.
Now let us enumerate some general rules for the analysis of programs. In general, the
running time of a statement or group of statements may be parameterized by the input size
and/or by one or more variables. The only permissible parameter for the running time of the
whole program is n, the input size.
1. The running time of each assignment, read, and write statement can usually be taken
to be O(1). There are a few exceptions, such as in PL/I, where assignments can
involve arbitrarily large arrays, and in any language that allows function calls in
assignment statements.
2. The running time of a sequence of statements is determined by the sum rule. That is,
the running time of the sequence is, to within a constant factor, the largest running
time of any statement in the sequence.
3. The running time of an if-statement is the cost of the conditionally executed
statements, plus the time for evaluating the condition. The time to evaluate the
condition is normally O(1). The time for an if-then-else construct is the time to
evaluate the condition plus the larger of the time needed for the statements executed
when the condition is true and the time for the statements executed when the
condition is false.
4. The time to execute a loop is the sum, over all times around the loop, of the time to
execute the body and the time to evaluate the condition for termination (usually the
latter is O(1)). Often this time is, neglecting constant factors, the product of the
number of times around the loop and the largest possible time for one execution of
the body, but we must consider each loop separately to make sure. The number of
iterations around a loop is usually clear, but there are times when the number of
iterations cannot be computed precisely. It could even be that the program is not an
algorithm, and there is no limit to the number of times we go around certain loops.
Procedure Calls
If we have a program with procedures, none of which is recursive, then we can compute the
running time of the various procedures one at a time, starting with those procedures that
make no calls on other procedures. (Remember to count a function invocation as a "call.")
There must be at least one such procedure, else at least one procedure is recursive. We can
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (22 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
then evaluate the running time of procedures that call only procedures that make no calls,
using the already-evaluated running times of the called procedures. We continue this
process, evaluating the running time of each procedure after the running times of all
procedures it calls have been evaluated.
If there are recursive procedures, then we cannot find an ordering of all the procedures
so that each calls only previously evaluated procedures. What we must now do is associate
with each recursive procedure an unknown time function T(n), where n measures the size of
the arguments to the procedure. We can then get a recurrence for T(n), that is, an equation
for T(n) in terms of T(k) for various values of k.
Techniques for solving many different kinds of recurrences exist; we shall present some
of these in Chapter 9. Here we shall show how to analyze a simple recursive program.
Example 1.10. Figure 1.14 gives a recursive program to compute n!, the product of all the
integers from 1 to n inclusive.
An appropriate size measure for this function is the value of n. Let T(n) be the running
time for fact(n). The running time for lines (1) and (2) is O(1), and for line (3) it is O(1) +
T(n-1). Thus, for some constants c and d,
function fact ( n: integer ): integer;
{ fact(n) computes n! }
begin
(1) if n <= 1 then
(2) fact := 1
else
(3) fact := n * fact(n-1)
end; { fact }
Fig. 1.14. Receursive program to compute factorials.
Assuming n > 2, we can expand T(n-1) in (1.1) to obtain
T(n) = 2c + T(n-2) if n > 2
That is, T(n-1) = c + T(n-2), as can be seen by substituting n-1 for n in (1.1). Thus, we may
substitute c + T(n-2) for T(n-1) in the equation T(n) = c + T(n-1). We can then use (1.1) to
expand T(n-2) to obtain
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (23 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
T(n) = 3c + T(n-3) if n > 3
and so on. In general,
T(n) = ic + T(n-i) if n > i
Finally, when i = n-1 we get
T(n) = c(n-1) + T(1) = c(n-1) + d (1.2)
From (1.2) we can conclude that T(n) is O(n). We should note that in this analysis we have
assumed that the multiplication of two integers is an O(1) operation. In practice, however,
we cannot use the program in Fig. 1.14 to compute n! for large values of n, because the size
of the integers being computed will exceed the word length of the underlying machine.
The general method for solving recurrence equations, as typified by Example 1.10, is
repeatedly to replace terms T(k) on the right side of the equation by the entire right side
with k substituted for n, until we obtain a formula in which T does not appear on the right
as in (1.2). Often we must then sum a series or, if we cannot sum it exactly, get a close
upper bound on the sum to obtain an upper bound on T(n).
Programs with GOTO's
In analyzing the running time of a program we have tacitly assumed that all flow of control
within a procedure was determined by branching and 1ooping constructs. We relied on this
fact as we determined the running time of progressively larger groups of statements by
assuming that we needed only the sum rule to group sequences of statements together. Goto
statments, however, make the logical grouping of statements more complex. For this
reason, goto statements should be avoided, but Pascal lacks break- and continue-statements
to jump out of loops. The goto-statement is often used as a substitute for statements of this
nature in Pascal.
We suggest the following approach to handling goto's that jump from a loop to code that
is guaranteed to follow the loop, which is generally the only kind of goto that is justified.
As the goto is presumably executed conditionally within the loop, we may pretend that it is
never taken. Because the goto takes us to a statement that will be executed after the loop
completes, this assumption is conservative; we can never underestimate the worst case
running time of the program if we assume the loop runs to completion. However, it is a rare
program in which ignoring the goto is so conservative that it causes us to overestimate the
growth rate of the worst case running time for the program. Notice that if we were faced
with a goto that jumped back to previously executed code we could not ignore it safely,
since that goto may create a loop that accounts for the bulk of the running time.
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (24 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
We should not leave the impression that the use of backwards goto's by themselves
make running times unanalyzable. As long as the loops of a program have a reasonable
structure, that is, each pair of loops are either disjoint or nested one within the other, then
the approach to running time analysis described in this section will work. (However, it
becomes the responsibility of the analyzer to ascertain what the loop structure is.) Thus, we
should not hesitate to apply these methods of program analysis to a language like Fortran,
where goto's are essential, but where programs written in the language tend to have a
reasonable loop structure.
Analyzing a Pseudo-Program
If we know the growth rate of the time needed to execute informal English statements, we
can analyze pseudo-programs just as we do real ones. Often, however, we do not know the
time to be spent on not-fully-implemented parts of a pseudo-program. For example, if we
have a pseudo-program in which the only unimplemented parts are operations on ADT's,
one of several implementations for an ADT may be chosen, and the overall running time
may depend heavily on the implementation. Indeed, one of the reasons for writing
programs in terms of ADT's is so we can consider the trade-offs among the running times
of the various operations that we obtain by different implementations.
To analyze pseudo-programs consisting of programming language statements and calls
to unimplemented procedures, such as operations on ADT's, we compute the running time
as a function of unspecified running times for each procedure. The running time for a
procedure will be parameterized by the "size" of the argument or arguments for that
procedure. Just as for "input size," the appropriate measure of size for an argument is a
matter for the analyzer to decide. If the procedure is an operation on an ADT, then the
underlying mathematical model for the ADT often indicates the logical notion of size. For
example, if the ADT is based on sets, the number of elements in a set is often the right
notion of size. In the remaining chapters we shall see many examples of analyzing the
running time of pseudo-programs.
1.6 Good Programming Practice
There are a substantial number of ideas we should bear in mind when designing an
algorithm and implementing it as a program. These ideas often appear platitudinous,
because by-and-large they can be appreciated only through their successful use in real
problems, rather than by development of a theory. They are sufficiently important,
however, that they are worth repeating here. The reader should watch for the application of
these ideas in the programs designed in this book, as well as looking for opportunities to
put them into practice in his own programs.
1. Plan the design of a program. We mentioned in Section 1.1 how a program can be
designed by first sketching the algorithm informally, then as a pseudo-program, and
gradually refining the pseudo-program until it becomes executable code. This
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (25 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms
strategy of sketch-then-detail tends to produce a more organized final program that
is easier to debug and maintain.
2. Encapsulate. Use procedures and ADT's to place the code for each principal
operation and type of data in one place in the program listing. Then, if changes
become necessary, the section of code requiring change will be localized.
3. Use or modify an existing program. One of the chief inefficiencies in the
programming process is that usually a project is tackled as if it were the first
program ever written. One should first look for an existing program that does all or a
part of the task. Conversely, when writing a program, one should consider making it
available to others for possibly unanticipated uses.
4. Be a toolsmith. In programming parlance, a tool is a program with a variety of uses.
When writing a program, consider whether it could be written in a somewhat more
general way with little extra effort. For example, suppose one is assigned the task of
writing a program to schedule final examinations. Instead, write a tool that takes an
arbitrary graph and colors the vertices with as few colors as possible, so that no two
vertices connected by an edge have the same color. In the context of examination
scheduling, the vertices are classes, the colors are examination periods, and an edge
between two classes means that the classes have a student in common. The coloring
program, together with routines that translate class lists into graphs and colors into
specific times and days, is the examination scheduler. However, the coloring
program can be used for problems totally unrelated to examination scheduling, such
as the traffic light problem of Section 1.1.
5. Program at the command level. Often we cannot find in a library the one program
needed to do a job, nor can we adapt one tool to do the job. A well-designed
operating system will allow us to connect a network of available programs together
without writing any programs at all, except for one list of operating system
commands. To make commands composable, it is generally necessary that each
behave as a filter, a program with one input file and one output file. Notice that any
number of filters can be composed, and if the command language of the operating
system is intelligently designed, merely listing the commands in the order in which
they are to be performed will suffice as a program.
Example 1.11. As an example, let us consider the program spell, as it was originally
written by S.C. Johnson from UNIX† commands. This program takes as input a file
f1consisting of English text and produces as output all those words in f1that are not found in
a small dictionary.‡ spell tends to list proper names as misspellings and may also list real
words not in its dictionary, but the typical output of spell is short enough that it can be
scanned by eye, and human intelligence can be used to determine whether a word in the
output of spell is a misspelling. (This book was checked using spell.)
The first filter used by spell is a command called translate that, given appropriate
parameters, replaces capital letters by lower case letters and blanks by newlines, leaving
http://www.ourstillwaters.org/stillwaters/csteaching/DataStructuresAndAlgorithms/mf1201.htm (26 of 37) [1.7.2001 18:58:22]
Data Structures and Algorithms: CHAPTER 1: Design and Analysis of Algorithms

